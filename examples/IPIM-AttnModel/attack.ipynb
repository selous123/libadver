{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.transforms as torch_transforms\n",
    "from networks import AttnVGG, VGG\n",
    "from loss import FocalLoss\n",
    "from data import preprocess_data_2016, preprocess_data_2017, ISIC\n",
    "from utilities import *\n",
    "from transforms import *\n",
    "\n",
    "print(\"======>load pretrained models\")\n",
    "net = AttnVGG(num_classes=2, attention=True, normalize_attn=True)\n",
    "# net = VGG(num_classes=2, gap=False)\n",
    "checkpoint = torch.load('models/checkpoint.pth')\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "pretrained_clf = nn.DataParallel(net).cuda()\n",
    "pretrained_clf.eval()\n",
    "\n",
    "print(\"=======>load ISIC2016 dataset\")\n",
    "normalize = Normalize((0.7012, 0.5517, 0.4875), (0.0942, 0.1331, 0.1521))\n",
    "transform_test = torch_transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "testset = ISIC(csv_file='test.csv', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=8)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with open('test_results.csv', 'wt', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images_test, labels_test = data['image'], data['label']\n",
    "        images_test, labels_test = images_test.cuda(), labels_test.cuda()\n",
    "        pred_test, __, __ = pretrained_clf.forward(images_test)\n",
    "        predict = torch.argmax(pred_test, 1)\n",
    "        total += labels_test.size(0)\n",
    "        correct += torch.eq(predict, labels_test).sum().double().item()\n",
    "        # record test predicted responses\n",
    "        responses = F.softmax(pred_test, dim=1).squeeze().detach().cpu().numpy()\n",
    "        responses = [responses[i] for i in range(responses.shape[0])]\n",
    "        csv_writer.writerows(responses)\n",
    "        # log images\n",
    "        if True:\n",
    "            I_test = utils.make_grid(images_test, nrow=8, normalize=True, scale_each=True)\n",
    "            #writer.add_image('test/image', I_test, i)\n",
    "            torchvision.utils.save_image(images_test, \"test/test_image.jpg\", nrow=8, normalize=True)\n",
    "            # accention maps\n",
    "            if True:\n",
    "                __, a1, a2 = pretrained_clf.forward(images_test)\n",
    "                if a1 is not None:\n",
    "                    attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "                    torchvision.utils.save_image(attn1, \"test/att1.jpg\")\n",
    "                    #writer.add_image('test/attention_map_1', attn1, i)\n",
    "                if a2 is not None:\n",
    "                    attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "                    torchvision.utils.save_image(attn2, \"test/att2.jpg\")\n",
    "                    #writer.add_image('test/attention_map_2', attn2, i)\n",
    "AP, AUC, precision_mean, precision_mel, recall_mean, recall_mel = compute_metrics('test_results.csv', 'test.csv')\n",
    "print(\"\\ntest result: accuracy %.2f%%\" % (100*correct/total))\n",
    "print(\"\\nmean precision %.2f%% mean recall %.2f%% \\nprecision for mel %.2f%% recall for mel %.2f%%\" %\n",
    "        (100*precision_mean, 100*recall_mean, 100*precision_mel, 100*recall_mel))\n",
    "print(\"\\nAP %.4f AUC %.4f\\n\" % (AP, AUC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libadver.attack as attack\n",
    "(./xx.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lrh/program/git/pytorch-example/Adversarial_Perturbations/adversarial/libadver/libadver/utils.py:46: UserWarning: Code Running Environment is not in Terminal, we can not invoke progress_bar!!\n",
      "  warnings.warn(\"Code Running Environment is not in Terminal, we can not invoke progress_bar!!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======>load pretrained models\n",
      "=======>load ISIC2016 dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.transforms as torch_transforms\n",
    "from networks import AttnVGG, VGG\n",
    "from loss import FocalLoss\n",
    "from data import preprocess_data_2016, preprocess_data_2017, ISIC\n",
    "from utilities import *\n",
    "from transforms import *\n",
    "import libadver.attack as attack\n",
    "\n",
    "modelFile = \"/home/lrh/program/git/pytorch-example/adversarial-miccai2019/isic2016/IPMI2019-AttnMel/models/checkpoint.pth\"\n",
    "testCSVFile = \"/home/lrh/program/git/pytorch-example/adversarial-miccai2019/isic2016/IPMI2019-AttnMel/test.csv\"\n",
    "print(\"======>load pretrained models\")\n",
    "net = AttnVGG(num_classes=2, attention=True, normalize_attn=True, vis = False)\n",
    "# net = VGG(num_classes=2, gap=False)\n",
    "checkpoint = torch.load(modelFile)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "pretrained_clf = nn.DataParallel(net).cuda()\n",
    "pretrained_clf.eval()\n",
    "\n",
    "print(\"=======>load ISIC2016 dataset\")\n",
    "normalize = Normalize((0.7012, 0.5517, 0.4875), (0.0942, 0.1331, 0.1521))\n",
    "transform_test = torch_transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "testset = ISIC(csv_file=testCSVFile, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGD attack\n",
    "1. dataset attack\n",
    "2. single image attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "\n",
    "pgd_params = {\n",
    "            'ord': np.inf,\n",
    "            'y': None,\n",
    "            'eps': 5.0 / 255,\n",
    "            'eps_iter': 2.5 / 255,\n",
    "            'nb_iter': 5,\n",
    "            'rand_init': True,\n",
    "            'rand_minmax': 5.0 / 255,\n",
    "            'clip_min': 0.,\n",
    "            'clip_max': 1.,\n",
    "            'sanity_checks': True\n",
    "        }\n",
    "\n",
    "import libadver.attack as attack\n",
    "PGDAttack = attack.ProjectGradientDescent(model = pretrained_clf)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "resultPath = 'adversarial_result/PGD/test_delete.csv'\n",
    "\n",
    "with open(resultPath, 'wt', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        image, label = data['image'], data['label']\n",
    "        image, label = image.cuda(), label.cuda()\n",
    "        \n",
    "        pgd_params['y'] = label\n",
    "        pgd_params['clip_min'] = torch.min(image) \n",
    "        pgd_params['clip_max'] = torch.max(image)\n",
    "        \n",
    "        adv_x = PGDAttack.generate(image, **pgd_params)\n",
    "        \n",
    "        pred_test, __, __ = pretrained_clf(adv_x)\n",
    "        predict = torch.argmax(pred_test, 1)\n",
    "        total += label.size(0)\n",
    "        correct += torch.eq(predict, label).sum().double().item()\n",
    "        # record test predicted responses\n",
    "        responses = F.softmax(pred_test, dim=1).squeeze().detach().cpu().numpy()\n",
    "        responses = [responses[i] for i in range(responses.shape[0])]\n",
    "        csv_writer.writerows(responses)\n",
    "        # log images\n",
    "        I_test = utils.make_grid(image, nrow=8, normalize=True, scale_each=True)\n",
    "        #writer.add_image('test/image', I_test, i)\n",
    "        torchvision.utils.save_image(image, \"adversarial_result/PGD/test_image.jpg\", nrow=8, normalize=True)\n",
    "        torchvision.utils.save_image(adv_x, \"adversarial_result/PGD/adv_image.jpg\", nrow=8, normalize=True)\n",
    "        \n",
    "        # original attention maps\n",
    "        __, a1, a2 = pretrained_clf(image)\n",
    "        if a1 is not None:\n",
    "            attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "            torchvision.utils.save_image(attn1, \"adversarial_result/PGD/att1.jpg\")\n",
    "            #writer.add_image('test/attention_map_1', attn1, i)\n",
    "        if a2 is not None:\n",
    "            attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "            torchvision.utils.save_image(attn2, \"adversarial_result/PGD/att2.jpg\")\n",
    "            \n",
    "        # adversarial attention maps\n",
    "        __, a1, a2 = pretrained_clf(adv_x)\n",
    "        if a1 is not None:\n",
    "            attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "            torchvision.utils.save_image(attn1, \"adversarial_result/PGD/adv_att1.jpg\")\n",
    "            #writer.add_image('test/attention_map_1', attn1, i)\n",
    "        if a2 is not None:\n",
    "            attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "            torchvision.utils.save_image(attn2, \"adversarial_result/PGD/adv_att2.jpg\")\n",
    "        break\n",
    "                    #writer.add_image('test/attention_map_2', attn2, i)\n",
    "# AP, AUC, precision_mean, precision_mel, recall_mean, recall_mel = compute_metrics(resultPath, 'test.csv')\n",
    "# print(\"\\ntest result: accuracy %.2f%%\" % (100*correct/total))\n",
    "# print(\"\\nmean precision %.2f%% mean recall %.2f%% \\nprecision for mel %.2f%% recall for mel %.2f%%\" %\n",
    "#         (100*precision_mean, 100*recall_mean, 100*precision_mel, 100*recall_mel))\n",
    "# print(\"\\nAP %.4f AUC %.4f\\n\" % (AP, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "resultPath = \"adversarial_result/PGD/test_m5n5.csv\"\n",
    "testCSVFile = \"/home/lrh/program/git/pytorch-example/adversarial-miccai2019/isic2016/IPMI2019-AttnMel/test.csv\"\n",
    "AP, AUC, precision_mean, precision_mel, recall_mean, recall_mel = compute_metrics(resultPath, testCSVFile)\n",
    "#print(\"\\ntest result: accuracy %.2f%%\" % (100*correct/total))\n",
    "print(\"\\nmean precision %.2f%% mean recall %.2f%% \\nprecision for mel %.2f%% recall for mel %.2f%%\" %\n",
    "        (100*precision_mean, 100*recall_mean, 100*precision_mel, 100*recall_mel))\n",
    "print(\"\\nAP %.4f AUC %.4f\\n\" % (AP, AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Image Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0107, 0.9893],\n",
      "        [0.1566, 0.8434],\n",
      "        [0.1271, 0.8729],\n",
      "        [0.0069, 0.9931],\n",
      "        [0.2915, 0.7085]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[1.0000e+00, 3.7414e-29],\n",
      "        [1.0000e+00, 1.5114e-28],\n",
      "        [1.0000e+00, 1.1361e-24],\n",
      "        [1.0000e+00, 1.4895e-28],\n",
      "        [1.0000e+00, 6.6416e-31]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "from transforms import *\n",
    "import libadver\n",
    "\n",
    "pgd_params = {\n",
    "            'ord': np.inf,\n",
    "            'y': None,\n",
    "            'eps': 5.0 / 255,\n",
    "            'eps_iter': 1.25 / 255,\n",
    "            'nb_iter': 10,\n",
    "            'rand_init': True,\n",
    "            'rand_minmax': 5.0 / 255,\n",
    "            'clip_min': 0.,\n",
    "            'clip_max': 1.,\n",
    "            'sanity_checks': True\n",
    "        }\n",
    "\n",
    "pgd_params['y'] = torch.LongTensor([1,1,1,1,1]).cuda()\n",
    "\n",
    "\n",
    "import libadver.attack as attack\n",
    "PGDAttack = attack.ProjectGradientDescent(model = pretrained_clf)\n",
    "isBenign = False\n",
    "benignRoot = \"./adversarial_result/ori_img/benign\"\n",
    "malignantRoot = \"./adversarial_result/ori_img/malignant\"\n",
    "\n",
    "benignImgs = [\n",
    "    \"ISIC_0000234.jpg\",\"ISIC_0000254.jpg\", \"ISIC_0000271.jpg\", \n",
    "    \"ISIC_0000325.jpg\",\"ISIC_0000319.jpg\"\n",
    "]\n",
    "malignImgs = [\n",
    "    \"ISIC_0000549.jpg\", \"ISIC_0001103.jpg\", \"ISIC_0001142.jpg\",\n",
    "    \"ISIC_0000547.jpg\", \"ISIC_0001100.jpg\"\n",
    "]\n",
    "\n",
    "if isBenign is True:\n",
    "    Imgs = benignImgs\n",
    "    Root = benignRoot\n",
    "else:\n",
    "    Imgs = malignImgs\n",
    "    Root = malignantRoot\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "mean = [0.7012, 0.5517, 0.4875]\n",
    "std = [0.0942, 0.1331, 0.1521]\n",
    "normalize = Normalize(mean, std)\n",
    "transform_test = transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "\n",
    "images = torch.zeros([5,3,224,224])\n",
    "labels = torch.zeros([5])\n",
    "from PIL import Image\n",
    "for batchIdx, Img in enumerate(Imgs):\n",
    "    benignPath = os.path.join(Root, Img)\n",
    "    img = Image.open(benignPath)\n",
    "    sample = {'image': img, 'image_seg': img, 'label': 0}\n",
    "    t_sample = transform_test(sample)\n",
    "    img = t_sample[\"image\"]\n",
    "    #img.unsqueeze_(0)\n",
    "    images[batchIdx] = img\n",
    "    labels[batchIdx] = t_sample['label']\n",
    "    #print(images.shape)\n",
    "# print(img1.shape)\n",
    "images = images.cuda()\n",
    "pgd_params['clip_min'] = torch.min(images) \n",
    "pgd_params['clip_max'] = torch.max(images)\n",
    "\n",
    "# img1_temp = torch.zeros(img1.size())\n",
    "# for c2 in range(3):\n",
    "#     img1_temp.data[:,c2,:,:] = (img1.data[:,c2,:,:] * std[c2]) + mean[c2]\n",
    "# torchvision.utils.save_image(img1_temp, \"test/ori_img.jpg\", normalize=True,  scale_each=True)\n",
    "\n",
    "\n",
    "adv_images = PGDAttack.generate(images, **pgd_params)\n",
    "\n",
    "#torchvision.utils.save_image(images, \"adversarial_result/PGD/ori_img.png\", normalize=True,  scale_each=True)\n",
    "#torchvision.utils.save_image(adv_images, \"adversarial_result/PGD/adv_img.png\", normalize=True,  scale_each=True)\n",
    "delta_ims = adv_images - images\n",
    "#torchvision.utils.save_image(delta_ims, \"adversarial_result/PGD/delta_im.png\", normalize=True,  scale_each=True)\n",
    "\n",
    "\n",
    "pred_test, a1, a2 = pretrained_clf(images)\n",
    "print(torch.softmax(pred_test, dim=1))\n",
    "predict = torch.argmax(pred_test, 1)\n",
    "print(predict)\n",
    "\n",
    "pred_test, a1, a2 = pretrained_clf(adv_images)\n",
    "print(torch.softmax(pred_test, dim=1))\n",
    "predict = torch.argmax(pred_test, 1)\n",
    "print(predict)\n",
    "\n",
    "images = images.cpu()\n",
    "adv_images = adv_images.cpu()\n",
    "delta_ims = delta_ims.cpu()\n",
    "\n",
    "for i in range(5):\n",
    "    image = images[i]\n",
    "    image_PIL = libadver.visutils.recreate_image(image,mean,std)\n",
    "    libadver.visutils.save_image(image_PIL,\"adversarial_result/pre_img/malignant/ori_img_%d.png\" %i)\n",
    "    \n",
    "    adv_image = adv_images[i]\n",
    "    adv_image_PIL = libadver.visutils.recreate_image(adv_image,mean,std)\n",
    "    libadver.visutils.save_image(adv_image_PIL,\"adversarial_result/PGD/malignant/adv_img_%d.png\" %i)\n",
    "    \n",
    "    delta_im = delta_ims[i].data.numpy()\n",
    "    libadver.visutils.save_gradient_images(delta_im,\"adversarial_result/PGD/malignant/delta_im_%d.png\" %i)\n",
    "    \n",
    "    \n",
    "\n",
    "#I_test = utils.make_grid(img1.detach(), nrow=8, normalize=True, scale_each=True)\n",
    "\n",
    "# for c2 in range(3):\n",
    "#     img1_temp.data[:,c2,:,:] = (img1.data[:,c2,:,:] * std[c2]) + mean[c2]\n",
    "# torchvision.utils.save_image(img1_temp, \"test/adv_img.jpg\", normalize=True,  scale_each=True)\n",
    "\n",
    "# if a1 is not None:\n",
    "#     attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "#     torchvision.utils.save_image(attn1, \"test/adv_att1.jpg\")\n",
    "#     #writer.add_image('test/attention_map_1', attn1, i)\n",
    "# if a2 is not None:\n",
    "#     attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "#     torchvision.utils.save_image(attn2, \"test/adv_att2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [1,2,3]\n",
    "[-i for i in mean]\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libadver.visutils as vutils\n",
    "import libadver\n",
    "libadver.visutils.recreate_image\n",
    "\n",
    "#delta_ims = delta_ims.detach().cpu().numpy()\n",
    "#vutils.save_gradient_images(delta_ims[0],\"delta.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAP attack\n",
    "1. dataset attack\n",
    "2. single image attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libadver.attack as attack\n",
    "import libadver.models.generators as generators\n",
    "import torch.optim as optim\n",
    "mean = (0.7012, 0.5517, 0.4875)\n",
    "std = (0.0942, 0.1331, 0.1521)\n",
    "isTrain = True\n",
    "import torch\n",
    "\n",
    "params = {\n",
    "        \"attackModelPath\" : None,\n",
    "        \"mag_in\" : 7.0,\n",
    "        \"ord\" : \"inf\",\n",
    "        \"epochNum\" : 3,\n",
    "        \"criterion\" : nn.CrossEntropyLoss(),\n",
    "        \"ncInput\" : 3,\n",
    "        \"ncOutput\" : 3,\n",
    "        \"mean\" : mean,\n",
    "        \"std\" : std,\n",
    "        \"MaxIter\" : 100\n",
    "    }\n",
    "print(params)\n",
    "saveModelPath = \"adversarial_result/GAP_im_m7n3.pth\"\n",
    "attackModel = generators.define(input_nc = params[\"ncInput\"], output_nc = params[\"ncOutput\"],\n",
    "                                ngf = 64, gen_type = \"unet\", norm=\"batch\", act=\"relu\", gpu_ids = [0])\n",
    "    \n",
    "\n",
    "if isTrain is True:\n",
    "    print(\"===>Train\")\n",
    "    optimizerG = optim.Adam(attackModel.parameters(), lr = 2e-4, betas = (0.5, 0.999))\n",
    "    params[\"optimizerG\"] = optimizerG\n",
    "    GAPAttack = attack.GenerativeAdversarialPerturbations(pretrained_clf, attackModel, **params)\n",
    "    GAPAttack.train(testloader, saveModelPath)\n",
    "else:\n",
    "    print(\"===>Test\")\n",
    "    ## test\n",
    "    params[\"attackModelPath\"] = saveModelPath\n",
    "    GAPAttack = GenerativeAdversarialPerturbations(pretrained_clf, attackModel, **params)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, targets) in enumerate(testdataloader):\n",
    "        images, targets = images.cuda(), targets.cuda()\n",
    "        adv_images = GAPAttack.generate(images)\n",
    "        predicted = pretrained_clf(adv_images)\n",
    "        predicted_labels = torch.argmax(predicted,1)\n",
    "        #print(predicted_labels)\n",
    "        correct += torch.sum(predicted_labels.eq(targets))\n",
    "        #print(targets)\n",
    "        total += images.shape[0]\n",
    "        print(\"ACC:%.3f | %d,%d\" %(100.0*float(correct) / total, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visulization\n",
    "\n",
    "ori_img + conv1 feas + saliency maps + attention maps + Guided gradCam\n",
    "\n",
    "//vistools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libadver.visutils as visutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transforms import *\n",
    "from torchvision.transforms import transforms\n",
    "benignImg = \"./test/ori_img/ISIC_0000016_be.jpg\" #0\n",
    "malignImg = \"./test/ori_img/ISIC_0000074_ma.jpg\" #1\n",
    "target_class = 1\n",
    "img1 = Image.open(malignImg)\n",
    "\n",
    "mean = (0.7012, 0.5517, 0.4875)\n",
    "std = (0.0942, 0.1331, 0.1521)\n",
    "normalize = Normalize(mean, std)\n",
    "transform_test = transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "\n",
    "sample = {'image': img1, 'image_seg': img1, 'label': 0}\n",
    "\n",
    "t_sample = transform_test(sample)\n",
    "img1 = t_sample[\"image\"]\n",
    "img1.unsqueeze_(0)\n",
    "img1 = img1.cuda()\n",
    "\n",
    "x = img1\n",
    "x.requires_grad = True\n",
    "output,_,_ = pretrained_clf(x)\n",
    "one_hot_output = torch.FloatTensor(1, output.size()[-1]).zero_()\n",
    "one_hot_output[0][target_class] = 1\n",
    "one_hot_output = one_hot_output.cuda()\n",
    "# Backward pass\n",
    "output.backward(gradient=one_hot_output)\n",
    "print(x.grad.data.shape)\n",
    "gradient_arr = x.grad.data.cpu().numpy()[0]\n",
    "gradient_arr_grey = visutils.convert_to_grayscale(gradient_arr)\n",
    "print(gradient_arr_grey.shape)\n",
    "gradient_arr_grey = 1 - gradient_arr_grey\n",
    "visutils.save_gradient_images(gradient_arr_grey, \"test/malignImg_grey.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transforms import *\n",
    "from torchvision.transforms import transforms\n",
    "benignImg = \"./test/ori_img/ISIC_0000016_be.jpg\" #0\n",
    "malignImg = \"./test/ori_img/ISIC_0000074_ma.jpg\" #1\n",
    "target_class = 1\n",
    "img1 = Image.open(malignImg)\n",
    "\n",
    "mean = (0.7012, 0.5517, 0.4875)\n",
    "std = (0.0942, 0.1331, 0.1521)\n",
    "normalize = Normalize(mean, std)\n",
    "transform_test = transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "\n",
    "sample = {'image': img1, 'image_seg': img1, 'label': 0}\n",
    "\n",
    "t_sample = transform_test(sample)\n",
    "img1 = t_sample[\"image\"]\n",
    "img1.unsqueeze_(0)\n",
    "img1 = img1.cuda()\n",
    "\n",
    "x = img1\n",
    "_,_,_,block1,block2,block3,block4,block5 = pretrained_clf(x)\n",
    "\n",
    "print(block1.shape)\n",
    "import torchvision\n",
    "block1 = block1.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block1,\"test/block1.jpg\")\n",
    "\n",
    "block2 = block2.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block2,\"test/block2.jpg\")\n",
    "\n",
    "block3 = block3.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block3,\"test/block3.jpg\",nrow=32)\n",
    "\n",
    "block4 = block4.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block4,\"test/block4.jpg\",nrow=32)\n",
    "\n",
    "block5 = block5.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block5,\"test/block5.jpg\",nrow=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "crashes = sns.load_dataset(\"car_crashes\").sort_values(\"total\", ascending=False)[0:7]\n",
    "print(crashes.head())\n",
    "# 加载数据\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "# 创建图表\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"total\", y=\"abbrev\", data=crashes,\n",
    "            label=\"Total\", color=\"b\",edgecolor = 'w')\n",
    "# 设置第一个柱状图\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=\"alcohol\", y=\"abbrev\", data=crashes,\n",
    "            label=\"Alcohol-involved\", color=\"b\",edgecolor = 'w')\n",
    "# 设置第二个柱状图\n",
    "\n",
    "ax.legend(ncol=1, loc=\"lower right\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnext = models.resnext101_32x8d(pretrained=True)\n",
    "\n",
    "#print(resnext)\n",
    "\n",
    "resnet = models.resnet18()\n",
    "#print(resnet)\n",
    "\n",
    "print(resnext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
